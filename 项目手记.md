## Lab 1
尝试完成worker.go 代码主要负责向coordinater请求任务并执行。请求任务使用doHeartbeat(),并根据返回结构体中JobType 字段来决定执行什么任务

定义mr/rpc.go 中 HeartbeatResponse结构体，首要存储的内容是Id和JobType，根据JobType不同决定存入的其他字段是否有效
在util.go中定义JobType类型，同时定义任务类型常量块，使用iota初始化第一个常量，后续生成自增值

mr/worker.go doHeartBeat()函数，通过call()方法调用Coordinator.Heartbeat方法，传入构造的resp地址，获得返回值

继续完成worker根据不同HeartBeatResponse.JobType 调用的不同函数，包括doMap,doReduce,Wait和Complete

go的变量命名：
    变量名 类型名
go的函数名：
    函数名 func(参数类型) 返回值类型
make函数：
    make(chan int,[buffer_size])
    make(map[string]int){'key':1,...}
    make([][]int,5)


在doMap方法中，首先读入文件获得文件内容content并处理相关异常，再使用mapf函数处理，该方法返回 KeyValue结构体数组，

rules中指明map阶段需要将intermediate keys分入nReduce个bucket中（后续使用nReduce个reduce任务处理intermediate keys），同时每个map任务应该创建nReduce个intermediate文件

为每个bucket创建一个goroutine，每个goroutine将待存入这个bucket内的intermediate中的kv写入本地文件

make构造intermediate变量，类型为二维数组，D1作为nReduce_Bucket号，D2内append多个KeyValue对象

`var wg sync.WaitGroup`定义了一个WaitGroup对象，用于等待所有的goroutine完成，内置了计数器对象，wg.Wait()方法会阻塞，直到wg内置counter为0

`defer wg.Done()`用于在方法完成后减少wg计数器，TODO::思考在函数结束时直接调用wg.Done()和这种方式有什么区别？--defer方法确保了异常返回时也能调用wg.Done()而且避免了函数返回时忘记调用wg.Done()的情况。

使用:=声明局部变量，var声明全局/包级变量

fmt.Println/Printf()打印到标准输出，Sprint()返回格式化后的字符串,不打印到标准输出

Sprint和Sprintf --前者concat参数并返回，后者类似printf

%v是什么/%+v/%#v --自动选择输出类型，基本类型直接输出，复合类型输出易于阅读格式，自定义接口如果有Stringer方法则调用该方法;%#v：以 Go 语法表示值。%+v：对于结构体，包含字段名和值。%#v：对于结构体，包含字段名和值，并且使用 Go 语法表示

String()方法 --Stringer/Error/io.Reader/Writer/Closer/xxx等，都属于go语言内置接口

go func(xxx){

}(params) 用于自定义匿名函数调用

新建atomic.go存放原子操作
    实现原子写文件操作 --先写入临时文件再调用os.Rename()原子替换

>接收者:
`func [Receiver] [MethodName](args ...) (results ...){...}`通过指定接收者将方法与类型绑定起来（GO语言没有类）

doReport()方法
    用到了SchedulePhase和ReportReq&ReportResp结构体,结构体在rpc.go里，SPhase在util.go里，通过call函数RPC调用Coordinator中的Report函数

Coordinator.go/Report()&Heartbeat():
    先定义了coordinator.go/Task和Utils.go/TaskStatus, 又定义了heartbeatMsg和reportMsg
    Heartbeat():这里参数中传了一个空的Request struct，感觉没用？？TODO::检查HeartbeatReqest作用，没用就删了；在coordinator中，heartbeat函数把resp地址放入heartbeatCh中，然后等待msg.ok通道的信号（猜测这里用的是没有缓存的channel）这边是一个生产者消费者模型，消费者部分在schedule中实现
    推测同步机制是 Report/Heartbeat函数先将msg发送到Coordinator对应channel，然后执行流程交给其他函数（initPhase，schedule等），其他流程在完成时会在msg.ok这个channel里面塞一个struct，然后把执行流程交会Heartbeat，在其他流程执行过程中，由于resp地址塞到msg中，所以其他流程应该往里面写入了合适的数据；Report函数流程应该类似


doReduce():
    找一下nMap这个数字是哪里来的？写数据好像都在selectTask里面
    main/mrcoordinator.go中调用了MakeCoordinator(),这个函数的impl在coordinator里，这里展示了nMap是如何初始化的：根据需要coordinator处理的文件数初始化nMap；
    这里顺便完成下makeCoordinator这个函数
    考虑下nMap这个参数是干嘛的？？？

先写coordinator:

~~selectTask:
    1. 在task中维护开始时间和fileName
    2. 每次调用时检查一遍coordinator中的所有任务，如果闲置就根据coordinator的阶段分配MapTask/ReduceTask
    3. 如果Working中就检查是否超时，超时则根据当前阶段重新分配当前任务到worker
    4. Coordinator 分为3个调度阶段，MapPhase, ReducePhase, WaitPhase~~

Coordinator主要有三个目标，分配任务，状态管理，阶段切换
主要调度循环逻辑在schedule方法里：
任务流程应该是Map->Reduce->Done,所以先initMapPhase，该函数将codntor阶段改为MapPhase，然后把tasks填充起来
然后开一个死循环，使用switch 等待heartbeatCh/reportCh的信号
1. heartbeatCh 
    这里应该是worker向coordinator发送心跳，coordinator根据worker的状态，分配任务，返回结果
    要根据当前coordinator的阶段，分配任务，返回结果
    如果已经进入CompletePhase，就把CompleteJob写入resp的JobType类型然后在msg.ok写入空结构体发送信号，切换到worker.go/Worker函数执行，会return结束这个go routine.
    当非CompletePhase时，由于coordntor处理heartbeat的函数向hrtbtCh里写入请求消息（该消息携带一个resp地址和okch）
    此时， 取出hrtbtMsg,调用selectTask函数为该worker分配任务,根据selectTask方法返回情况，若该函数返回True表示当前阶段所有任务已经全部完成，返回False表示还有任务未完成;
    返回False时，向msg.ok中传入空结构体信号，切换到cordnator/Heartbeat执行->worker.go/doHeartbeat -> worker.go/Worker逐层返回，然后worker可以根据resp中存入的信息继续执行。
    //TODO:: 返回True时？
2. selectTask:
    该函数接受的参数中包含一个resp地址用于写入参数给worker使用
    功能上，该函数遍历coodnator的task列表，检查每个任务状态，闲置则启动，工作则检查超时；--每次hartbeat时才检查任务是否超时，所以只能保证在有新worker可用时分配一个已超时任务
    当检查到第一个闲置任务时，向当前resp中写入该任务相关参数，终止遍历task列表
    调用顺序如下：
        1. 从mrworker.go 启动worker
        2. worker doheartbeat()
        3. coordinator schedule() switch监听heartbeatCh, 在非CompletePhase时，把hrtbtMsg中的resp地址传入selectTask为当前提出hartbeat的worker分配任务
Coordinator全部完成
回到worker
在initReducePhase的时候，向coordinator.Tasks中插入了nReduce个任务，代表需要nReduce个go routine的reduce任务，每个reduce任务处理一个nMap个intermediate文件(回忆一下shuffle过程)
如何解释NMap（len(files)）呢？
--在initMapPhase中，将files中的文件名作为map任务的参数，然后启动nMap个map任务，每个map任务处理一个文件；在每个map任务中，把mapf的结果按照ihash()%nReduce出的index存放到nReduce个intermediate列表中，每个列表生成临时文件存储中间结果。

总体来说，我的Lab 1实现是Event-driven的，在worker中发送hrtbtRequest，coordinator每次收到request后根据内部存储的task信息做出响应，返回相应数据调度worker工作。
如果期待更高的并发量的话，可以使用多线程的coordinator，一种可能的实现是在每次heartbeat时起一个新的coordiator线程，互斥访问tasks数组（或者干脆把tasks数组做类似数据库分页操作，减少互斥访问）


channel命名域？
---------------------------------------------------------------------------------
## Lab 2
